{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1af2662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominikgeorgi/Library/Mobile Documents/com~apple~CloudDocs/IUBH/Rettungsdienst_Personalplanung/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "calls_pred vorbereiten:   0%|          | 0/12 [00:00<?, ?it/s]15:39:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:   8%|▊         | 1/12 [00:00<00:01,  7.70it/s]15:39:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  25%|██▌       | 3/12 [00:00<00:00,  9.45it/s]15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  42%|████▏     | 5/12 [00:00<00:00,  9.79it/s]15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  50%|█████     | 6/12 [00:00<00:00,  9.81it/s]15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  58%|█████▊    | 7/12 [00:00<00:00,  9.58it/s]15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  67%|██████▋   | 8/12 [00:00<00:00,  9.45it/s]15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  75%|███████▌  | 9/12 [00:00<00:00,  9.60it/s]15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  83%|████████▎ | 10/12 [00:01<00:00,  9.38it/s]15:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten:  92%|█████████▏| 11/12 [00:01<00:00,  9.16it/s]15:39:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "calls_pred vorbereiten: 100%|██████████| 12/12 [00:01<00:00,  9.05it/s]\n",
      "100%|██████████| 1151/1151 [16:45:37<00:00, 52.42s/it]     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groups</th>\n",
       "      <th>features</th>\n",
       "      <th>params</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>under</th>\n",
       "      <th>over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>season</td>\n",
       "      <td>[season_1, season_2, season_3]</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>98.463911</td>\n",
       "      <td>140.143300</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.791123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>season</td>\n",
       "      <td>[season_1, season_2, season_3]</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>98.819280</td>\n",
       "      <td>139.870530</td>\n",
       "      <td>0.203411</td>\n",
       "      <td>0.796589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>season</td>\n",
       "      <td>[season_1, season_2, season_3]</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>98.349393</td>\n",
       "      <td>139.502285</td>\n",
       "      <td>0.203322</td>\n",
       "      <td>0.796678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>season</td>\n",
       "      <td>[season_1, season_2, season_3]</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
       "      <td>98.365123</td>\n",
       "      <td>139.656489</td>\n",
       "      <td>0.203411</td>\n",
       "      <td>0.796589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>season</td>\n",
       "      <td>[season_1, season_2, season_3]</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>98.464584</td>\n",
       "      <td>140.299798</td>\n",
       "      <td>0.206100</td>\n",
       "      <td>0.793900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>cyclic_encoding_month+holiday_effects+holiday_...</td>\n",
       "      <td>[quarter_1, quarter_2, quarter_3, is_month_sta...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>87.199119</td>\n",
       "      <td>128.310762</td>\n",
       "      <td>0.248816</td>\n",
       "      <td>0.751184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>cyclic_encoding_month+holiday_effects+holiday_...</td>\n",
       "      <td>[quarter_1, quarter_2, quarter_3, is_month_sta...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>86.954909</td>\n",
       "      <td>128.169325</td>\n",
       "      <td>0.225781</td>\n",
       "      <td>0.774219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>cyclic_encoding_month+holiday_effects+holiday_...</td>\n",
       "      <td>[quarter_1, quarter_2, quarter_3, is_month_sta...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>89.163606</td>\n",
       "      <td>129.765742</td>\n",
       "      <td>0.221179</td>\n",
       "      <td>0.778821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>cyclic_encoding_month+holiday_effects+holiday_...</td>\n",
       "      <td>[quarter_1, quarter_2, quarter_3, is_month_sta...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
       "      <td>89.748083</td>\n",
       "      <td>128.823798</td>\n",
       "      <td>0.214939</td>\n",
       "      <td>0.785061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>cyclic_encoding_month+holiday_effects+holiday_...</td>\n",
       "      <td>[quarter_1, quarter_2, quarter_3, is_month_sta...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>87.315248</td>\n",
       "      <td>128.338701</td>\n",
       "      <td>0.240086</td>\n",
       "      <td>0.759914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5755 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 groups  \\\n",
       "0                                                season   \n",
       "1                                                season   \n",
       "2                                                season   \n",
       "3                                                season   \n",
       "4                                                season   \n",
       "...                                                 ...   \n",
       "5750  cyclic_encoding_month+holiday_effects+holiday_...   \n",
       "5751  cyclic_encoding_month+holiday_effects+holiday_...   \n",
       "5752  cyclic_encoding_month+holiday_effects+holiday_...   \n",
       "5753  cyclic_encoding_month+holiday_effects+holiday_...   \n",
       "5754  cyclic_encoding_month+holiday_effects+holiday_...   \n",
       "\n",
       "                                               features  \\\n",
       "0                        [season_1, season_2, season_3]   \n",
       "1                        [season_1, season_2, season_3]   \n",
       "2                        [season_1, season_2, season_3]   \n",
       "3                        [season_1, season_2, season_3]   \n",
       "4                        [season_1, season_2, season_3]   \n",
       "...                                                 ...   \n",
       "5750  [quarter_1, quarter_2, quarter_3, is_month_sta...   \n",
       "5751  [quarter_1, quarter_2, quarter_3, is_month_sta...   \n",
       "5752  [quarter_1, quarter_2, quarter_3, is_month_sta...   \n",
       "5753  [quarter_1, quarter_2, quarter_3, is_month_sta...   \n",
       "5754  [quarter_1, quarter_2, quarter_3, is_month_sta...   \n",
       "\n",
       "                                                 params        mae  \\\n",
       "0     {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  98.463911   \n",
       "1     {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...  98.819280   \n",
       "2     {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  98.349393   \n",
       "3     {'learning_rate': 0.05, 'max_depth': 8, 'n_est...  98.365123   \n",
       "4     {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  98.464584   \n",
       "...                                                 ...        ...   \n",
       "5750  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  87.199119   \n",
       "5751  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...  86.954909   \n",
       "5752  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  89.163606   \n",
       "5753  {'learning_rate': 0.05, 'max_depth': 8, 'n_est...  89.748083   \n",
       "5754  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  87.315248   \n",
       "\n",
       "            rmse     under      over  \n",
       "0     140.143300  0.208877  0.791123  \n",
       "1     139.870530  0.203411  0.796589  \n",
       "2     139.502285  0.203322  0.796678  \n",
       "3     139.656489  0.203411  0.796589  \n",
       "4     140.299798  0.206100  0.793900  \n",
       "...          ...       ...       ...  \n",
       "5750  128.310762  0.248816  0.751184  \n",
       "5751  128.169325  0.225781  0.774219  \n",
       "5752  129.765742  0.221179  0.778821  \n",
       "5753  128.823798  0.214939  0.785061  \n",
       "5754  128.338701  0.240086  0.759914  \n",
       "\n",
       "[5755 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groups</th>\n",
       "      <th>features</th>\n",
       "      <th>params</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>under</th>\n",
       "      <th>over</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>holiday+lag_target_short+roll_target_short+season</td>\n",
       "      <td>[season_1, season_2, season_3, holiday, holida...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>84.606324</td>\n",
       "      <td>123.592374</td>\n",
       "      <td>0.219739</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>71.249164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>holiday_window+lag_target_short+month_start_en...</td>\n",
       "      <td>[season_1, season_2, season_3, is_month_start,...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>83.889692</td>\n",
       "      <td>122.773388</td>\n",
       "      <td>0.233845</td>\n",
       "      <td>0.766155</td>\n",
       "      <td>71.352739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>holiday+lag_target_short+month_start_end+roll_...</td>\n",
       "      <td>[season_1, season_2, season_3, is_month_start,...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>83.482370</td>\n",
       "      <td>122.889572</td>\n",
       "      <td>0.239510</td>\n",
       "      <td>0.760490</td>\n",
       "      <td>71.491972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>holiday_effects+holiday_window+lag_target_shor...</td>\n",
       "      <td>[season_1, season_2, season_3, is_month_start,...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_esti...</td>\n",
       "      <td>85.471355</td>\n",
       "      <td>124.488825</td>\n",
       "      <td>0.214273</td>\n",
       "      <td>0.785727</td>\n",
       "      <td>71.558970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>holiday+lag_target_short+month_start_end+roll_...</td>\n",
       "      <td>[season_1, season_2, season_3, is_month_start,...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>83.551898</td>\n",
       "      <td>123.030407</td>\n",
       "      <td>0.240175</td>\n",
       "      <td>0.759825</td>\n",
       "      <td>71.581706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 groups  \\\n",
       "1636  holiday+lag_target_short+roll_target_short+season   \n",
       "2984  holiday_window+lag_target_short+month_start_en...   \n",
       "2954  holiday+lag_target_short+month_start_end+roll_...   \n",
       "4561  holiday_effects+holiday_window+lag_target_shor...   \n",
       "4514  holiday+lag_target_short+month_start_end+roll_...   \n",
       "\n",
       "                                               features  \\\n",
       "1636  [season_1, season_2, season_3, holiday, holida...   \n",
       "2984  [season_1, season_2, season_3, is_month_start,...   \n",
       "2954  [season_1, season_2, season_3, is_month_start,...   \n",
       "4561  [season_1, season_2, season_3, is_month_start,...   \n",
       "4514  [season_1, season_2, season_3, is_month_start,...   \n",
       "\n",
       "                                                 params        mae  \\\n",
       "1636  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...  84.606324   \n",
       "2984  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  83.889692   \n",
       "2954  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  83.482370   \n",
       "4561  {'learning_rate': 0.1, 'max_depth': 6, 'n_esti...  85.471355   \n",
       "4514  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...  83.551898   \n",
       "\n",
       "            rmse     under      over      score  \n",
       "1636  123.592374  0.219739  0.780261  71.249164  \n",
       "2984  122.773388  0.233845  0.766155  71.352739  \n",
       "2954  122.889572  0.239510  0.760490  71.491972  \n",
       "4561  124.488825  0.214273  0.785727  71.558970  \n",
       "4514  123.030407  0.240175  0.759825  71.581706  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# notebooks/prophet_gridsearch_parallel_optimized.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "import os\n",
    "from random import seed, sample\n",
    "\n",
    "# --------------------------------------\n",
    "# 1. Daten laden\n",
    "# --------------------------------------\n",
    "df = pd.read_parquet(\"../data/processed/sickness_table.parquet\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.asfreq('D')\n",
    "df[\"ds\"] = df.index\n",
    "\n",
    "holiday_df = pd.read_parquet(\"../data/processed/holiday.parquet\")\n",
    "holiday_df = pd.DataFrame({\n",
    "    \"holiday\": holiday_df[\"name\"],\n",
    "    \"ds\": holiday_df[\"date\"],\n",
    "    \"lower_window\": -2,\n",
    "    \"upper_window\": 2\n",
    "})\n",
    "\n",
    "# --------------------------------------\n",
    "# 2. Feature Grid vorbereiten\n",
    "# --------------------------------------\n",
    "grid = {\n",
    "    \"season\": [\"season_1\", \"season_2\", \"season_3\"],\n",
    "    \"quarter\": [\"quarter_1\", \"quarter_2\", \"quarter_3\"],\n",
    "    \"month_start_end\": [\"is_month_start\", \"is_month_end\"],\n",
    "    \"cyclic_encoding_weekday\": [\"weekday_sin\", \"weekday_cos\"],\n",
    "    \"cyclic_encoding_month\": [\"month_sin\", \"month_cos\"],\n",
    "    \"weekend\": [\"is_weekend\"],\n",
    "    \"holiday\": [\"holiday\", \"holiday_before\", \"holiday_after\"],\n",
    "    \"holiday_sig\": [\"holiday_significant\", \"holiday_significant_before\", \"holiday_significant_after\"],\n",
    "    \"holiday_window\": [\"holiday_window\"],\n",
    "    \"holiday_effects\": [\n",
    "        \"holiday_cluster\", \"holiday_density_7d\", \"holiday_on_monday_or_friday\",\n",
    "        \"holiday_cluster_and_bruecke\", \"holiday_and_weekday_cat\"\n",
    "    ],\n",
    "    \"lag_target_short\": [\"lag_target_bereitschaft_1\", \"lag_target_bereitschaft_2\"],\n",
    "    \"roll_target_short\": [\"roll_target_bereitschaft_mean_7\", \"roll_target_bereitschaft_std_7\",\n",
    "                           \"roll_target_bereitschaft_min_7\", \"roll_target_bereitschaft_max_7\"]\n",
    "}\n",
    "\n",
    "all_combinations = []\n",
    "keys = list(grid.keys())\n",
    "holiday_groups = {\"holiday\", \"holiday_sig\", \"holiday_window\"}\n",
    "season_groups = {\"season\", \"quarter\"}\n",
    "week_groups = {\"cyclic_encoding_weekday\", \"weekend\"}\n",
    "\n",
    "for r in range(1, len(keys) + 1):\n",
    "    for combo in itertools.combinations(keys, r):\n",
    "        # Nur eine holiday-Gruppe pro Kombination zulassen\n",
    "        holiday_included = [k for k in combo if k in holiday_groups]\n",
    "        if len(holiday_included) > 1:\n",
    "            continue  # überspringe diese Kombination\n",
    "\n",
    "        # Nur eine season-Gruppe pro Kombination zulassen\n",
    "        season_included = [k for k in combo if k in season_groups]\n",
    "        if len(season_included) > 1:\n",
    "            continue  # überspringe diese Kombination\n",
    "\n",
    "        # Nur eine week-Gruppe pro Kombination zulassen\n",
    "        week_included = [k for k in combo if k in week_groups]\n",
    "        if len(week_included) > 1:\n",
    "            continue  # überspringe diese Kombination\n",
    "\n",
    "        feature_list = []\n",
    "        for key in combo:\n",
    "            feature_list.extend(grid[key])\n",
    "        group_name = \"+\".join(sorted(combo))\n",
    "        all_combinations.append({\n",
    "            \"groups\": group_name,\n",
    "            \"features\": feature_list\n",
    "        })\n",
    "\n",
    "df_combinations = pd.DataFrame(all_combinations)\n",
    "\n",
    "# --------------------------------------\n",
    "# 3. Parameter Grid & CV Splits\n",
    "# --------------------------------------\n",
    "\n",
    "# Teil 1: Fixe Kombinationen\n",
    "fixed_params = [\n",
    "    {\"learning_rate\": 0.1, \"max_depth\": 8, \"n_estimators\": 300, \"num_leaves\": 15, \"reg_alpha\": 0.1, \"reg_lambda\": 0.0},\n",
    "    {\"learning_rate\": 0.1, \"max_depth\": 6, \"n_estimators\": 300, \"num_leaves\": 15, \"reg_alpha\": 0.1, \"reg_lambda\": 0.0},\n",
    "    {\"learning_rate\": 0.1, \"max_depth\": 8, \"n_estimators\": 300, \"num_leaves\": 10, \"reg_alpha\": 0.1, \"reg_lambda\": 0.0},\n",
    "    {\"learning_rate\": 0.05, \"max_depth\": 8, \"n_estimators\": 300, \"num_leaves\": 15, \"reg_alpha\": 0.1, \"reg_lambda\": 0.0},\n",
    "    {\"learning_rate\": 0.1, \"max_depth\": 8, \"n_estimators\": 300, \"num_leaves\": 15, \"reg_alpha\": 0.1, \"reg_lambda\": 0.1},\n",
    "]\n",
    "\n",
    "# Teil 2: Randomisierte Kombinationen aus breitem Grid\n",
    "param_grid_random = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.15],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"num_leaves\": [10, 15, 25],\n",
    "    \"reg_alpha\": [0.0, 0.1],\n",
    "    \"reg_lambda\": [0.0, 0.1],\n",
    "}\n",
    "seed(42)\n",
    "param_names = list(param_grid_random.keys())\n",
    "full_space = list(itertools.product(*param_grid_random.values()))\n",
    "random_10 = sample(full_space, 10)\n",
    "random_params = [dict(zip(param_names, vals)) for vals in random_10]\n",
    "\n",
    "# Teil 3: Extreme Kombinationen (Spannweite)\n",
    "extreme_params = [\n",
    "    {\"learning_rate\": 0.15, \"max_depth\": 4, \"n_estimators\": 100, \"num_leaves\": 10, \"reg_alpha\": 0.0, \"reg_lambda\": 0.0},\n",
    "    {\"learning_rate\": 0.1,  \"max_depth\": 10, \"n_estimators\": 300, \"num_leaves\": 50, \"reg_alpha\": 0.3, \"reg_lambda\": 0.0},\n",
    "    {\"learning_rate\": 0.05, \"max_depth\": 4,  \"n_estimators\": 200, \"num_leaves\": 10, \"reg_alpha\": 0.2, \"reg_lambda\": 0.2},\n",
    "    {\"learning_rate\": 0.01, \"max_depth\": 8,  \"n_estimators\": 400, \"num_leaves\": 31, \"reg_alpha\": 0.1, \"reg_lambda\": 0.1},\n",
    "    {\"learning_rate\": 0.1,  \"max_depth\": 2,  \"n_estimators\": 100, \"num_leaves\": 7,  \"reg_alpha\": 0.0, \"reg_lambda\": 0.0},\n",
    "]\n",
    "\n",
    "# Finale Liste (20 Kombinationen)\n",
    "all_params = fixed_params#+ random_params + extreme_params\n",
    "\n",
    "min_train_days = 730\n",
    "split_start = df[\"ds\"].min() + pd.Timedelta(days=min_train_days)\n",
    "split_end = df[\"ds\"].max()\n",
    "splits = []\n",
    "\n",
    "current = pd.Timestamp(split_start.year, split_start.month, 15)\n",
    "if split_start.day > 15:\n",
    "    current += relativedelta(months=1)\n",
    "\n",
    "while current + relativedelta(months=1) <= split_end:\n",
    "    train_end = current\n",
    "    test_start = (train_end + relativedelta(months=1)).replace(day=1)\n",
    "    test_end = test_start + pd.offsets.MonthEnd(0)\n",
    "    if test_end <= split_end:\n",
    "        splits.append((train_end, test_start, test_end))\n",
    "    current += relativedelta(months=1)\n",
    "\n",
    "# --------------------------------------\n",
    "# 5. Prophet-Forecasts vorberechnen\n",
    "# --------------------------------------\n",
    "best_models = pd.read_parquet(\"../models/prophet/best_params.parquet\")\n",
    "best_model = best_models.iloc[0]\n",
    "df_calls_input = df.rename(columns={\"calls\": \"y\"})\n",
    "\n",
    "prophet_cache = {}\n",
    "\n",
    "def predict_calls(train_end):\n",
    "    if train_end in prophet_cache:\n",
    "        return prophet_cache[train_end]\n",
    "\n",
    "    forecast_start = (train_end + pd.offsets.MonthBegin(1)).replace(day=1)\n",
    "    forecast_end = forecast_start + pd.offsets.MonthEnd(0)\n",
    "    forecast_dates = pd.date_range(start=forecast_start, end=forecast_end, freq=\"D\")\n",
    "\n",
    "    df_train = df_calls_input.loc[:train_end].copy()\n",
    "    df_model = df_train[[\"ds\", \"y\"] + list(best_model[\"features\"])].copy()\n",
    "\n",
    "    model = Prophet(\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=True,\n",
    "        holidays=holiday_df if best_model[\"groups\"].endswith(\"+H\") else None,\n",
    "        **best_model[\"params\"]\n",
    "    )\n",
    "    for feat in best_model[\"features\"]:\n",
    "        model.add_regressor(feat)\n",
    "\n",
    "    model.fit(df_model)\n",
    "    df_forecast_input = df.loc[forecast_dates][[\"ds\"] + list(best_model[\"features\"])].copy()\n",
    "    forecast = model.predict(df_forecast_input)\n",
    "    df_forecast = df_forecast_input.copy()\n",
    "    df_forecast[\"calls_pred\"] = forecast[\"yhat\"].values\n",
    "    prophet_cache[train_end] = df_forecast[[\"ds\", \"calls_pred\"]]\n",
    "    return prophet_cache[train_end]\n",
    "\n",
    "calls_forecasts = {train_end: predict_calls(train_end) for train_end, _, _ in tqdm(splits, desc=\"calls_pred vorbereiten\")}\n",
    "\n",
    "# --------------------------------------\n",
    "# 6. Evaluation mit Zwischenspeicherung\n",
    "# --------------------------------------\n",
    "partial_results = []\n",
    "\n",
    "def evaluate_combination(group_string, features, params):\n",
    "    fold_metrics = []\n",
    "\n",
    "    for train_end, test_start, test_end in splits:\n",
    "        try:\n",
    "            df_calls_pred = calls_forecasts[train_end]\n",
    "\n",
    "            df_train = df.loc[:train_end].copy()\n",
    "            df_train[\"calls_pred\"] = df_train[\"calls\"]\n",
    "\n",
    "            df_test = df.loc[test_start:test_end].copy()\n",
    "            df_test = df_test.merge(df_calls_pred, on=\"ds\", how=\"left\")\n",
    "\n",
    "            input_cols = [\"target_bereitschaft\", \"calls_pred\"] + features\n",
    "\n",
    "            df_train = df_train[[\"ds\"] + input_cols]\n",
    "            df_test = df_test[[\"ds\"] + input_cols]\n",
    "\n",
    "            X_train = df_train.set_index(\"ds\")[[\"calls_pred\"] + features]\n",
    "            y_train = df_train.set_index(\"ds\")[\"target_bereitschaft\"]\n",
    "\n",
    "            model = LGBMRegressor(\n",
    "                objective='quantile', alpha=0.9,\n",
    "                random_state=42, verbose=-1, **params\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_hist = df_train.set_index(\"ds\")[\"target_bereitschaft\"].copy()\n",
    "            preds = []\n",
    "\n",
    "            df_test_indexed = df_test.set_index(\"ds\")\n",
    "\n",
    "            for date in df_test_indexed.index:\n",
    "                row = pd.DataFrame(index=[date])\n",
    "\n",
    "                # Dynamische Lag-Features berechnen\n",
    "                for feat in features:\n",
    "                    if feat.startswith(\"lag_target_bereitschaft\"):\n",
    "                        try:\n",
    "                            lag = int(feat.split(\"_\")[-1])\n",
    "                            row[feat] = y_hist.get(date - pd.Timedelta(days=lag), np.nan)\n",
    "                        except Exception:\n",
    "                            print(f\"[Warnung] Fehler bei Lag-Feature: {feat}\")\n",
    "\n",
    "                    elif feat.startswith(\"roll_target_bereitschaft\"):\n",
    "                        try:\n",
    "                            parts = feat.split(\"_\")\n",
    "                            stat = parts[-2]\n",
    "                            win = int(parts[-1])\n",
    "                            ts = date - pd.Timedelta(days=1)\n",
    "                            series = y_hist.shift(1).rolling(window=win, min_periods=1)\n",
    "                            if stat == \"mean\":\n",
    "                                row[feat] = series.mean().get(ts, np.nan)\n",
    "                            elif stat == \"std\":\n",
    "                                row[feat] = series.std().get(ts, np.nan)\n",
    "                            elif stat == \"min\":\n",
    "                                row[feat] = series.min().get(ts, np.nan)\n",
    "                            elif stat == \"max\":\n",
    "                                row[feat] = series.max().get(ts, np.nan)\n",
    "                        except Exception:\n",
    "                            print(f\"[Warnung] Fehler bei Rolling-Feature: {feat}\")\n",
    "\n",
    "                # Statische Features aus df_test\n",
    "                static_feats = [f for f in features if not (f.startswith(\"lag_\") or f.startswith(\"roll_\"))]\n",
    "                for feat in static_feats:\n",
    "                    row[feat] = df_test_indexed.at[date, feat]\n",
    "\n",
    "                # calls_pred einfügen\n",
    "                row[\"calls_pred\"] = df_test_indexed.at[date, \"calls_pred\"]\n",
    "\n",
    "                # Relevante Spalten selektieren und vervollständigen\n",
    "                row = row[[\"calls_pred\"] + features].bfill().ffill()\n",
    "\n",
    "                # Vorhersage und Update\n",
    "                pred = model.predict(row)[0]\n",
    "                preds.append((date, pred))\n",
    "                y_hist.loc[date] = pred\n",
    "\n",
    "            df_preds = pd.DataFrame(preds, columns=[\"ds\", \"yhat\"]).set_index(\"ds\")\n",
    "            df_test_indexed[\"yhat\"] = df_preds[\"yhat\"]\n",
    "\n",
    "            df_test_indexed[\"under\"] = (df_test_indexed[\"yhat\"] < df_test_indexed[\"target_bereitschaft\"]).astype(int)\n",
    "            df_test_indexed[\"over\"] = (df_test_indexed[\"yhat\"] > df_test_indexed[\"target_bereitschaft\"]).astype(int)\n",
    "\n",
    "            fold_metrics.append({\n",
    "                \"mae\": mean_absolute_error(df_test_indexed[\"target_bereitschaft\"], df_test_indexed[\"yhat\"]),\n",
    "                \"rmse\": sqrt(mean_squared_error(df_test_indexed[\"target_bereitschaft\"], df_test_indexed[\"yhat\"])),\n",
    "                \"under\": df_test_indexed[\"under\"].mean(),\n",
    "                \"over\": df_test_indexed[\"over\"].mean()\n",
    "            })\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"[Fehler] Gruppe={group_string} | Params={params}\")\n",
    "            return None\n",
    "\n",
    "    if fold_metrics:\n",
    "        avg = pd.DataFrame(fold_metrics).mean().to_dict()\n",
    "        result = {\n",
    "            \"groups\": group_string,\n",
    "            \"features\": features,\n",
    "            \"params\": params,\n",
    "            \"mae\": avg[\"mae\"],\n",
    "            \"rmse\": avg[\"rmse\"],\n",
    "            \"under\": avg[\"under\"],\n",
    "            \"over\": avg[\"over\"]\n",
    "        }\n",
    "        return result\n",
    "\n",
    "    return None\n",
    "\n",
    "# --------------------------------------\n",
    "# 7. Parallelisierung starten\n",
    "# --------------------------------------\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "results = Parallel(n_jobs=num_cores, batch_size=1)(\n",
    "    delayed(evaluate_combination)(row[\"groups\"], row[\"features\"], params)\n",
    "    for _, row in tqdm(df_combinations.iterrows(), total=len(df_combinations))\n",
    "    for params in all_params\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# 5. Ergebnisse speichern\n",
    "# --------------------------------------\n",
    "# Nach Berechnung aller Ergebnisse\n",
    "results = [r for r in results if r is not None]\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Speicherpfade\n",
    "results_path = os.path.abspath(\"../results/lgbm/cv_metrics_full.parquet\")\n",
    "models_path = os.path.abspath(\"../models/lgbm/best_params.parquet\")\n",
    "\n",
    "# Ordner anlegen\n",
    "os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(models_path), exist_ok=True)\n",
    "display(results_df)\n",
    "# Score berechnen und sortieren\n",
    "results_df[\"score\"] = (\n",
    "    results_df[\"mae\"] * 0.3 +\n",
    "    results_df[\"rmse\"] * 0.3 +\n",
    "    results_df[\"under\"] * 100 * 0.4\n",
    ")\n",
    "best_models = results_df.sort_values(\"score\")\n",
    "\n",
    "# Speichern\n",
    "results_df.to_parquet(results_path, index=False)\n",
    "best_models.to_parquet(models_path, index=False)\n",
    "display(best_models.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
